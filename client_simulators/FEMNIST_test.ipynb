{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0cd856d-080b-402e-b076-9e0f7f2cf09a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0cd856d-080b-402e-b076-9e0f7f2cf09a",
    "outputId": "f8d014f5-b952-4c4f-87a6-253c2cf45520"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import glob\n",
    "import json\n",
    "import numpy\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#import matplotlib.pyplot as plt\n",
    "from numpy import vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fZUak1ZUMUo4",
   "metadata": {
    "id": "fZUak1ZUMUo4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2788998ca1d74a3ab090f1dd189b67c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = \"/home/ubuntu/capstone/HorizontalHFL/datasets/FEMNIST\"\n",
    "\n",
    "def getUsers():\n",
    "  users = []\n",
    "  path = dir_path + \"/train/*.json\"\n",
    "  for file in tqdm(glob.glob(path)):\n",
    "    # print(\"processing: \" + file)\n",
    "    with open(file) as f:\n",
    "      dict_ = json.load(f);\n",
    "      for user in dict_['users']:\n",
    "        users.append(user)\n",
    "  return users\n",
    "\n",
    "def GetFile(path, clientID):\n",
    "  for file in glob.glob(path):\n",
    "    with open(file) as f:\n",
    "      dict_ = json.load(f);\n",
    "      for user in dict_['users']:\n",
    "        if user == clientID:\n",
    "          return file;\n",
    "\n",
    "users = getUsers()\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eaf69bf-d8bd-4df0-b0ca-ef251aebf882",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eaf69bf-d8bd-4df0-b0ca-ef251aebf882",
    "outputId": "5dd72a4b-876f-417c-9e75-310921c2a3a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0692_03 has 219 samples\n",
      "f0692_03 has 25 samples\n"
     ]
    }
   ],
   "source": [
    "#train_data = torchvision.datasets.EMNIST('.', 'mnist', download='True', train='True', transform=transforms.ToTensor())\n",
    "#test_data = torchvision.datasets.EMNIST('.', 'mnist', download='True', train='False', transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "class FEMNISTDataset(Dataset):\n",
    "  def __init__(self, test, clientID):\n",
    "    self.images = []\n",
    "    self.labels = []\n",
    "    # Find file with the client ID, get its data\n",
    "    if test:\n",
    "      path = dir_path + \"/test/*.json\"\n",
    "    else:\n",
    "      path = dir_path + \"/train/*.json\"\n",
    "    file = GetFile(path, clientID)\n",
    "    with open(file) as f:\n",
    "      dict = json.load(f)\n",
    "      index = dict['users'].index(clientID)\n",
    "      self.numSamples = dict['num_samples'][index]\n",
    "      print(str(clientID) + \" has \" + str(self.numSamples) + \" samples\")\n",
    "      self.images = dict['user_data'][clientID]['x']\n",
    "      self.labels = dict['user_data'][clientID]['y']\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.numSamples\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    image = numpy.array(self.images[idx]).reshape(1,28,28)\n",
    "    img_tensor = torch.from_numpy(image).float()\n",
    "    label_id = torch.tensor(self.labels[idx])\n",
    "    return img_tensor, label_id\n",
    "\n",
    "\n",
    "\n",
    "train_data = FEMNISTDataset(False, users[80])\n",
    "test_data = FEMNISTDataset(True, users[80])\n",
    "\n",
    "trainLoader = DataLoader(train_data, batch_size=20, drop_last=True)\n",
    "testLoader = DataLoader(test_data, batch_size=10, drop_last=False)\n",
    "\n",
    "#img, label = train_data[2]\n",
    "#plt.figure()\n",
    "#plt.title(label)\n",
    "#plt.axis(\"off\")\n",
    "#plt.imshow(img, cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da43be0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 0, Label: tensor([2, 3, 5, 7, 1, 8, 3, 9, 9, 6]), Image size: torch.Size([10, 1, 28, 28])\n",
      "Batch Number: 1, Label: tensor([ 9,  6,  6, 61, 47, 42, 11, 28, 28, 47]), Image size: torch.Size([10, 1, 28, 28])\n",
      "Batch Number: 2, Label: tensor([21, 11, 21, 35, 24]), Image size: torch.Size([5, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for ii, (img_, label_) in enumerate(testLoader):\n",
    "    print(f'Batch Number: {ii}, Label: {label_}, Image size: {img_.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32591fe5-891e-4830-8696-d25b2f3b9e63",
   "metadata": {
    "id": "32591fe5-891e-4830-8696-d25b2f3b9e63"
   },
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 62)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f13b0c-88a7-4926-857c-a788f946ff76",
   "metadata": {
    "id": "d7f13b0c-88a7-4926-857c-a788f946ff76"
   },
   "outputs": [],
   "source": [
    "def train_model(trainLoader, model, epochs):\n",
    "    log_interval = 10\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "    model.train()\n",
    "    # enumerate epochs\n",
    "    for epoch in trange(epochs):\n",
    "        # print(\"starting epoch %d\" % epoch)\n",
    "        # enumerate mini batches\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainLoader):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "            \n",
    "        if epoch % log_interval == 0:\n",
    "            print(f'Train Epoch: {epoch:<2} \\tLoss: {loss.item():.6f}')\n",
    "          # acc = evaluate_model(testLoader, model)\n",
    "          # print('Accuracy: %.3f' % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b118b628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb091c69a904faca2c8972c4438e9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0  \tLoss: 4.096976\n",
      "Train Epoch: 10 \tLoss: 3.466539\n",
      "Train Epoch: 20 \tLoss: 2.308545\n",
      "Train Epoch: 30 \tLoss: 1.023801\n",
      "Train Epoch: 40 \tLoss: 1.155928\n",
      "Train Epoch: 50 \tLoss: 0.725960\n",
      "Train Epoch: 60 \tLoss: 1.292399\n",
      "Train Epoch: 70 \tLoss: 0.389874\n",
      "Train Epoch: 80 \tLoss: 0.777501\n",
      "Train Epoch: 90 \tLoss: 0.634902\n",
      "Train Epoch: 100 \tLoss: 1.529010\n",
      "Train Epoch: 110 \tLoss: 0.735609\n",
      "Train Epoch: 120 \tLoss: 1.138335\n",
      "Train Epoch: 130 \tLoss: 1.424874\n",
      "Train Epoch: 140 \tLoss: 1.079714\n",
      "Train Epoch: 150 \tLoss: 2.573204\n",
      "Train Epoch: 160 \tLoss: 1.359037\n",
      "Train Epoch: 170 \tLoss: 1.253479\n",
      "Train Epoch: 180 \tLoss: 1.148955\n",
      "Train Epoch: 190 \tLoss: 1.505768\n"
     ]
    }
   ],
   "source": [
    "model = CustomCNN()\n",
    "# print(model)\n",
    "train_model(trainLoader, model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d602e3a-5f09-4a59-b173-23461012808b",
   "metadata": {
    "id": "0d602e3a-5f09-4a59-b173-23461012808b"
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate_model(testLoader, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(testLoader):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # round to class values\n",
    "        yhat = yhat.argmax(axis=1)\n",
    "        yhat = yhat.reshape((len(yhat), 1))\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cefd84dd-f618-4f2e-a659-eeaed1ec1768",
   "metadata": {
    "id": "cefd84dd-f618-4f2e-a659-eeaed1ec1768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.400\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_model(testLoader, model)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b026c4-e7b3-4e86-92a9-52b6f0682190",
   "metadata": {
    "id": "72b026c4-e7b3-4e86-92a9-52b6f0682190"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FEMNIST_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
