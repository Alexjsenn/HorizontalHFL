{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "FEMNIST_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0cd856d-080b-402e-b076-9e0f7f2cf09a",
        "outputId": "f8d014f5-b952-4c4f-87a6-253c2cf45520"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import glob\n",
        "import json\n",
        "import numpy\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "#import matplotlib.pyplot as plt\n",
        "from numpy import vstack\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "b0cd856d-080b-402e-b076-9e0f7f2cf09a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZUak1ZUMUo4"
      },
      "source": [
        "dir_path = \"/content/drive/My Drive/Capstone/FEMNIST\"\n",
        "\n",
        "def getUsers():\n",
        "  users = []\n",
        "  path = dir_path + \"/train/*.json\"\n",
        "  for file in glob.glob(path):\n",
        "    print(\"processing: \" + file)\n",
        "    with open(file) as f:\n",
        "      dict = json.load(f);\n",
        "      for user in dict['users']:\n",
        "        users.append(user)\n",
        "  return users\n",
        "\n",
        "def GetFile(path, clientID):\n",
        "  for file in glob.glob(path):\n",
        "    with open(file) as f:\n",
        "      dict = json.load(f);\n",
        "      for user in dict['users']:\n",
        "        if user == clientID:\n",
        "          return file;\n",
        "\n",
        "users = getUsers()\n",
        "len(users)"
      ],
      "id": "fZUak1ZUMUo4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eaf69bf-d8bd-4df0-b0ca-ef251aebf882",
        "outputId": "5dd72a4b-876f-417c-9e75-310921c2a3a2"
      },
      "source": [
        "#train_data = torchvision.datasets.EMNIST('.', 'mnist', download='True', train='True', transform=transforms.ToTensor())\n",
        "#test_data = torchvision.datasets.EMNIST('.', 'mnist', download='True', train='False', transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "class FEMNISTDataset(Dataset):\n",
        "  def __init__(self, test, clientID):\n",
        "    self.images = []\n",
        "    self.labels = []\n",
        "    # Find file with the client ID, get its data\n",
        "    if test:\n",
        "      path = dir_path + \"/test/*.json\"\n",
        "    else:\n",
        "      path = dir_path + \"/train/*.json\"\n",
        "    file = GetFile(path, clientID)\n",
        "    with open(file) as f:\n",
        "      dict = json.load(f)\n",
        "      index = dict['users'].index(clientID)\n",
        "      self.numSamples = dict['num_samples'][index]\n",
        "      print(str(clientID) + \" has \" + str(self.numSamples) + \" samples\")\n",
        "      self.images = dict['user_data'][clientID]['x']\n",
        "      self.labels = dict['user_data'][clientID]['y']\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.numSamples\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    image = numpy.array(self.images[idx]).reshape(1,28,28)\n",
        "    img_tensor = torch.from_numpy(image).float()\n",
        "    label_id = torch.tensor(self.labels[idx])\n",
        "    return img_tensor, label_id\n",
        "\n",
        "\n",
        "\n",
        "train_data = FEMNISTDataset(False, users[80])\n",
        "test_data = FEMNISTDataset(True, users[80])\n",
        "\n",
        "trainLoader = DataLoader(train_data, batch_size=64)\n",
        "testLoader = DataLoader(test_data, batch_size=1024)\n",
        "\n",
        "#img, label = train_data[2]\n",
        "#plt.figure()\n",
        "#plt.title(label)\n",
        "#plt.axis(\"off\")\n",
        "#plt.imshow(img, cmap=\"gray\")\n",
        "#plt.show()"
      ],
      "id": "1eaf69bf-d8bd-4df0-b0ca-ef251aebf882",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f0128_00 has 299 samples\n",
            "f0128_00 has 34 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32591fe5-891e-4830-8696-d25b2f3b9e63"
      },
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "                    nn.Conv2d(1, 24, kernel_size = (5,5), stride=1, padding=0),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.MaxPool2d(2, stride=2),\n",
        "                    nn.Conv2d(24, 48, kernel_size = (5,5), stride=1, padding=0),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.MaxPool2d(2, stride=2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features= 4*4*48, out_features= 256),\n",
        "            nn.Linear(in_features= 256, out_features= 62))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x);\n",
        "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "        "
      ],
      "id": "32591fe5-891e-4830-8696-d25b2f3b9e63",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7f13b0c-88a7-4926-857c-a788f946ff76"
      },
      "source": [
        "def train_model(trainLoader, model, epochs):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    # enumerate epochs\n",
        "    for epoch in range(epochs):\n",
        "        print(\"starting epoch %d\" % epoch)\n",
        "        # enumerate mini batches\n",
        "        for i, (inputs, targets) in enumerate(trainLoader):\n",
        "            # clear the gradients\n",
        "            optimizer.zero_grad()\n",
        "            # compute the model output\n",
        "            yhat = model(inputs)\n",
        "            # calculate loss\n",
        "            loss = criterion(yhat, targets)\n",
        "            # credit assignment\n",
        "            loss.backward()\n",
        "            # update model weights\n",
        "            optimizer.step()\n",
        "        acc = evaluate_model(testLoader, model)\n",
        "        print('Accuracy: %.3f' % acc)\n"
      ],
      "id": "d7f13b0c-88a7-4926-857c-a788f946ff76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d602e3a-5f09-4a59-b173-23461012808b"
      },
      "source": [
        "# evaluate the model\n",
        "def evaluate_model(testLoader, model):\n",
        "    predictions, actuals = list(), list()\n",
        "    for i, (inputs, targets) in enumerate(testLoader):\n",
        "        # evaluate the model on the test set\n",
        "        yhat = model(inputs)\n",
        "        # retrieve numpy array\n",
        "        yhat = yhat.detach().numpy()\n",
        "        actual = targets.numpy()\n",
        "        actual = actual.reshape((len(actual), 1))\n",
        "        # round to class values\n",
        "        yhat = yhat.argmax(axis=1)\n",
        "        yhat = yhat.reshape((len(yhat), 1))\n",
        "        # store\n",
        "        predictions.append(yhat)\n",
        "        actuals.append(actual)\n",
        "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
        "    # calculate accuracy\n",
        "    acc = accuracy_score(actuals, predictions)\n",
        "    return acc"
      ],
      "id": "0d602e3a-5f09-4a59-b173-23461012808b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50059898-3153-43f5-86fb-44e9e1b1a06e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8cf998-3188-4626-b2c4-285e0ad236b7"
      },
      "source": [
        "model = CustomCNN()\n",
        "print(model)\n",
        "train_model(trainLoader, model, 100)\n",
        "print('Finished')"
      ],
      "id": "50059898-3153-43f5-86fb-44e9e1b1a06e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomCNN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 24, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(24, 48, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=62, bias=True)\n",
            "  )\n",
            ")\n",
            "starting epoch 0\n",
            "Accuracy: 0.000\n",
            "starting epoch 1\n",
            "Accuracy: 0.059\n",
            "starting epoch 2\n",
            "Accuracy: 0.059\n",
            "starting epoch 3\n",
            "Accuracy: 0.059\n",
            "starting epoch 4\n",
            "Accuracy: 0.000\n",
            "starting epoch 5\n",
            "Accuracy: 0.059\n",
            "starting epoch 6\n",
            "Accuracy: 0.059\n",
            "starting epoch 7\n",
            "Accuracy: 0.059\n",
            "starting epoch 8\n",
            "Accuracy: 0.059\n",
            "starting epoch 9\n",
            "Accuracy: 0.059\n",
            "starting epoch 10\n",
            "Accuracy: 0.059\n",
            "starting epoch 11\n",
            "Accuracy: 0.059\n",
            "starting epoch 12\n",
            "Accuracy: 0.059\n",
            "starting epoch 13\n",
            "Accuracy: 0.059\n",
            "starting epoch 14\n",
            "Accuracy: 0.059\n",
            "starting epoch 15\n",
            "Accuracy: 0.059\n",
            "starting epoch 16\n",
            "Accuracy: 0.059\n",
            "starting epoch 17\n",
            "Accuracy: 0.059\n",
            "starting epoch 18\n",
            "Accuracy: 0.059\n",
            "starting epoch 19\n",
            "Accuracy: 0.118\n",
            "starting epoch 20\n",
            "Accuracy: 0.235\n",
            "starting epoch 21\n",
            "Accuracy: 0.294\n",
            "starting epoch 22\n",
            "Accuracy: 0.324\n",
            "starting epoch 23\n",
            "Accuracy: 0.294\n",
            "starting epoch 24\n",
            "Accuracy: 0.294\n",
            "starting epoch 25\n",
            "Accuracy: 0.294\n",
            "starting epoch 26\n",
            "Accuracy: 0.324\n",
            "starting epoch 27\n",
            "Accuracy: 0.324\n",
            "starting epoch 28\n",
            "Accuracy: 0.353\n",
            "starting epoch 29\n",
            "Accuracy: 0.412\n",
            "starting epoch 30\n",
            "Accuracy: 0.412\n",
            "starting epoch 31\n",
            "Accuracy: 0.441\n",
            "starting epoch 32\n",
            "Accuracy: 0.471\n",
            "starting epoch 33\n",
            "Accuracy: 0.529\n",
            "starting epoch 34\n",
            "Accuracy: 0.588\n",
            "starting epoch 35\n",
            "Accuracy: 0.618\n",
            "starting epoch 36\n",
            "Accuracy: 0.647\n",
            "starting epoch 37\n",
            "Accuracy: 0.618\n",
            "starting epoch 38\n",
            "Accuracy: 0.676\n",
            "starting epoch 39\n",
            "Accuracy: 0.618\n",
            "starting epoch 40\n",
            "Accuracy: 0.647\n",
            "starting epoch 41\n",
            "Accuracy: 0.706\n",
            "starting epoch 42\n",
            "Accuracy: 0.647\n",
            "starting epoch 43\n",
            "Accuracy: 0.647\n",
            "starting epoch 44\n",
            "Accuracy: 0.676\n",
            "starting epoch 45\n",
            "Accuracy: 0.765\n",
            "starting epoch 46\n",
            "Accuracy: 0.676\n",
            "starting epoch 47\n",
            "Accuracy: 0.735\n",
            "starting epoch 48\n",
            "Accuracy: 0.706\n",
            "starting epoch 49\n",
            "Accuracy: 0.735\n",
            "starting epoch 50\n",
            "Accuracy: 0.735\n",
            "starting epoch 51\n",
            "Accuracy: 0.706\n",
            "starting epoch 52\n",
            "Accuracy: 0.676\n",
            "starting epoch 53\n",
            "Accuracy: 0.765\n",
            "starting epoch 54\n",
            "Accuracy: 0.706\n",
            "starting epoch 55\n",
            "Accuracy: 0.765\n",
            "starting epoch 56\n",
            "Accuracy: 0.794\n",
            "starting epoch 57\n",
            "Accuracy: 0.765\n",
            "starting epoch 58\n",
            "Accuracy: 0.735\n",
            "starting epoch 59\n",
            "Accuracy: 0.735\n",
            "starting epoch 60\n",
            "Accuracy: 0.794\n",
            "starting epoch 61\n",
            "Accuracy: 0.765\n",
            "starting epoch 62\n",
            "Accuracy: 0.735\n",
            "starting epoch 63\n",
            "Accuracy: 0.765\n",
            "starting epoch 64\n",
            "Accuracy: 0.765\n",
            "starting epoch 65\n",
            "Accuracy: 0.765\n",
            "starting epoch 66\n",
            "Accuracy: 0.765\n",
            "starting epoch 67\n",
            "Accuracy: 0.765\n",
            "starting epoch 68\n",
            "Accuracy: 0.765\n",
            "starting epoch 69\n",
            "Accuracy: 0.765\n",
            "starting epoch 70\n",
            "Accuracy: 0.765\n",
            "starting epoch 71\n",
            "Accuracy: 0.765\n",
            "starting epoch 72\n",
            "Accuracy: 0.765\n",
            "starting epoch 73\n",
            "Accuracy: 0.765\n",
            "starting epoch 74\n",
            "Accuracy: 0.765\n",
            "starting epoch 75\n",
            "Accuracy: 0.765\n",
            "starting epoch 76\n",
            "Accuracy: 0.765\n",
            "starting epoch 77\n",
            "Accuracy: 0.765\n",
            "starting epoch 78\n",
            "Accuracy: 0.765\n",
            "starting epoch 79\n",
            "Accuracy: 0.765\n",
            "starting epoch 80\n",
            "Accuracy: 0.765\n",
            "starting epoch 81\n",
            "Accuracy: 0.765\n",
            "starting epoch 82\n",
            "Accuracy: 0.765\n",
            "starting epoch 83\n",
            "Accuracy: 0.765\n",
            "starting epoch 84\n",
            "Accuracy: 0.765\n",
            "starting epoch 85\n",
            "Accuracy: 0.765\n",
            "starting epoch 86\n",
            "Accuracy: 0.765\n",
            "starting epoch 87\n",
            "Accuracy: 0.765\n",
            "starting epoch 88\n",
            "Accuracy: 0.765\n",
            "starting epoch 89\n",
            "Accuracy: 0.765\n",
            "starting epoch 90\n",
            "Accuracy: 0.765\n",
            "starting epoch 91\n",
            "Accuracy: 0.765\n",
            "starting epoch 92\n",
            "Accuracy: 0.765\n",
            "starting epoch 93\n",
            "Accuracy: 0.765\n",
            "starting epoch 94\n",
            "Accuracy: 0.765\n",
            "starting epoch 95\n",
            "Accuracy: 0.765\n",
            "starting epoch 96\n",
            "Accuracy: 0.765\n",
            "starting epoch 97\n",
            "Accuracy: 0.765\n",
            "starting epoch 98\n",
            "Accuracy: 0.765\n",
            "starting epoch 99\n",
            "Accuracy: 0.765\n",
            "Finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cefd84dd-f618-4f2e-a659-eeaed1ec1768"
      },
      "source": [
        ""
      ],
      "id": "cefd84dd-f618-4f2e-a659-eeaed1ec1768",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72b026c4-e7b3-4e86-92a9-52b6f0682190"
      },
      "source": [
        ""
      ],
      "id": "72b026c4-e7b3-4e86-92a9-52b6f0682190",
      "execution_count": null,
      "outputs": []
    }
  ]
}